# Guide d'Utilisation - Azure Speech to Text API

Ce guide explique comment utiliser les nouveaux endpoints de reconnaissance vocale.

## ğŸ“‹ Configuration Requise

### 1. Ajouter les clÃ©s Azure Speech dans `.env`

```env
AZURE_SPEECH_KEY=your_azure_speech_key_here
AZURE_SPEECH_REGION=francecentral
```

### 2. Installer les dÃ©pendances

```powershell
pip install -r requirements.txt
```

## ğŸ¤ Endpoints Disponibles

### 1. `/api/speech/languages` (GET)
Obtenir la liste des langues supportÃ©es.

**RequÃªte :**
```powershell
curl http://localhost:5000/api/speech/languages
```

**RÃ©ponse :**
```json
{
  "languages": {
    "ar-SA": "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© (Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©)",
    "ar-EG": "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© (Ù…ØµØ±)",
    "ar-MA": "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© (Ø§Ù„Ù…ØºØ±Ø¨)",
    "fr-FR": "FranÃ§ais (France)"
  },
  "status": "success"
}
```

### 2. `/api/speech-to-text` (POST)
Convertir un fichier audio en texte uniquement.

**Formats audio supportÃ©s :** WAV, MP3, OGG, WebM, M4A, FLAC

**RequÃªte :**
```powershell
# Avec langue par dÃ©faut (ar-SA)
curl -X POST http://localhost:5000/api/speech-to-text `
  -F "audio=@recording.wav"

# Avec langue spÃ©cifique
curl -X POST http://localhost:5000/api/speech-to-text `
  -F "audio=@recording.wav" `
  -F "language=ar-MA"
```

**RÃ©ponse :**
```json
{
  "text": "Ù…Ø±Ø­Ø¨Ø§ØŒ Ø£Ø±ÙŠØ¯ Ù…Ø¹Ø±ÙØ© Ø­Ø§Ù„Ø© Ø®Ø¯Ù…ØªÙŠ",
  "language": "ar-SA",
  "status": "success"
}
```

### 3. `/api/speech-to-chat` (POST)
Convertir audio en texte ET envoyer directement au chat agent.

**RequÃªte :**
```powershell
# Premier message (nouvelle conversation)
curl -X POST http://localhost:5000/api/speech-to-chat `
  -F "audio=@recording.wav" `
  -F "language=ar-MA"

# Message suivant (conversation existante)
curl -X POST http://localhost:5000/api/speech-to-chat `
  -F "audio=@recording2.wav" `
  -F "conversation_id=550e8400-e29b-41d4-a716-446655440000"
```

**RÃ©ponse :**
```json
{
  "transcribed_text": "Ø±Ù‚Ù… CIL Ø§Ù„Ø®Ø§Øµ Ø¨ÙŠ Ù‡Ùˆ: 1071324-101",
  "response": "Ø´ÙƒØ±Ø§Ù‹ Ù„ØªÙ‚Ø¯ÙŠÙ… Ø±Ù‚Ù… CIL Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ...",
  "conversation_id": "550e8400-e29b-41d4-a716-446655440000",
  "is_new_conversation": false,
  "language": "ar-MA",
  "status": "success"
}
```

## ğŸ§ª Tests avec PowerShell

### Test 1 : Transcription simple
```powershell
# CrÃ©er un fichier audio de test (ou utiliser un existant)
$audioFile = "test_audio.wav"

# Envoyer pour transcription
$response = Invoke-RestMethod -Uri "http://localhost:5000/api/speech-to-text" `
  -Method POST `
  -Form @{
    audio = Get-Item $audioFile
    language = "ar-MA"
  }

Write-Host "Texte transcrit: $($response.text)"
```

### Test 2 : Audio vers chat (flux complet)
```powershell
# 1. Premier audio - crÃ©e une conversation
$response1 = Invoke-RestMethod -Uri "http://localhost:5000/api/speech-to-chat" `
  -Method POST `
  -Form @{
    audio = Get-Item "message1.wav"
    language = "ar-MA"
  }

$convId = $response1.conversation_id
Write-Host "Conversation crÃ©Ã©e: $convId"
Write-Host "Transcrit: $($response1.transcribed_text)"
Write-Host "RÃ©ponse: $($response1.response)"

# 2. DeuxiÃ¨me audio - continue la conversation
$response2 = Invoke-RestMethod -Uri "http://localhost:5000/api/speech-to-chat" `
  -Method POST `
  -Form @{
    audio = Get-Item "message2.wav"
    conversation_id = $convId
  }

Write-Host "Transcrit: $($response2.transcribed_text)"
Write-Host "RÃ©ponse: $($response2.response)"
```

### Test 3 : Avec fetch JavaScript (Frontend)
```javascript
async function sendAudioMessage(audioBlob, conversationId = null) {
  const formData = new FormData();
  formData.append('audio', audioBlob, 'recording.wav');
  formData.append('language', 'ar-MA');
  
  if (conversationId) {
    formData.append('conversation_id', conversationId);
  }
  
  const response = await fetch('/api/speech-to-chat', {
    method: 'POST',
    body: formData
  });
  
  const data = await response.json();
  
  console.log('Transcription:', data.transcribed_text);
  console.log('RÃ©ponse:', data.response);
  console.log('Conversation ID:', data.conversation_id);
  
  return data;
}
```

## ğŸ¯ Cas d'Usage

### ScÃ©nario 1 : Transcription seulement
```powershell
# Utilisateur enregistre un audio
# â†’ Envoie Ã  /api/speech-to-text
# â†’ ReÃ§oit le texte transcrit
# â†’ Peut Ã©diter le texte avant de l'envoyer au chat
```

### ScÃ©nario 2 : Flux vocal direct
```powershell
# Utilisateur enregistre un audio
# â†’ Envoie Ã  /api/speech-to-chat
# â†’ Transcription + traitement par l'agent en une seule requÃªte
# â†’ ReÃ§oit la rÃ©ponse directement
```

## ğŸ“ Notes Importantes

1. **Langues supportÃ©es** : L'arabe marocain (`ar-MA`) est recommandÃ© pour le Maroc
2. **Formats audio** : WAV est le plus fiable, mais MP3, OGG, WebM, M4A et FLAC sont aussi supportÃ©s
3. **Taille maximale** : 16MB (configurÃ© dans app.py)
4. **Nettoyage** : Les fichiers audio sont automatiquement supprimÃ©s aprÃ¨s traitement
5. **Conversation** : Le `conversation_id` est gÃ©rÃ© de la mÃªme faÃ§on que l'endpoint `/api/chat`

## âš ï¸ Gestion des Erreurs

**Erreur : "Azure Speech credentials not configured"**
â†’ VÃ©rifier que `AZURE_SPEECH_KEY` et `AZURE_SPEECH_REGION` sont dans `.env`

**Erreur : "No speech detected"**
â†’ L'audio est vide ou de mauvaise qualitÃ©

**Erreur : "File type not allowed"**
â†’ Utiliser un format supportÃ© (WAV, MP3, OGG, WebM, M4A, FLAC)

## ğŸš€ DÃ©marrage

```powershell
# 1. Configurer .env
# 2. Installer dÃ©pendances
pip install -r requirements.txt

# 3. DÃ©marrer le serveur
cd backend
python app.py

# 4. Tester
curl http://localhost:5000/api/speech/languages
```
